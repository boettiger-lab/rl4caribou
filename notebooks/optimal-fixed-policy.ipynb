{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba1c2a7a-d99f-499d-9481-f5516c547246",
   "metadata": {},
   "source": [
    "This notebook tries to search for optimal fixed policies (e.g. constant mortality) that maximize the objective (i.e. expected net reward). Here I try [scikit-optimize](https://scikit-optimize.github.io/stable/index.html) routines which are designed for noisy functions and compare to a brute-force parallel grid search.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f15d4b8e-ef57-4bce-899b-89bb32d396f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/rstudio/rl4fisheries\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: gymnasium in /opt/venv/lib/python3.10/site-packages (from rl4fisheries==1.0.0) (0.28.1)\n",
      "Requirement already satisfied: numpy in /opt/venv/lib/python3.10/site-packages (from rl4fisheries==1.0.0) (1.26.4)\n",
      "Requirement already satisfied: matplotlib in /opt/venv/lib/python3.10/site-packages (from rl4fisheries==1.0.0) (3.8.2)\n",
      "Requirement already satisfied: typing in /opt/venv/lib/python3.10/site-packages (from rl4fisheries==1.0.0) (3.7.4.3)\n",
      "Requirement already satisfied: jax-jumpy>=1.0.0 in /opt/venv/lib/python3.10/site-packages (from gymnasium->rl4fisheries==1.0.0) (1.0.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /opt/venv/lib/python3.10/site-packages (from gymnasium->rl4fisheries==1.0.0) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /opt/venv/lib/python3.10/site-packages (from gymnasium->rl4fisheries==1.0.0) (4.9.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /opt/venv/lib/python3.10/site-packages (from gymnasium->rl4fisheries==1.0.0) (0.0.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/venv/lib/python3.10/site-packages (from matplotlib->rl4fisheries==1.0.0) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/venv/lib/python3.10/site-packages (from matplotlib->rl4fisheries==1.0.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/venv/lib/python3.10/site-packages (from matplotlib->rl4fisheries==1.0.0) (4.48.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/venv/lib/python3.10/site-packages (from matplotlib->rl4fisheries==1.0.0) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/venv/lib/python3.10/site-packages (from matplotlib->rl4fisheries==1.0.0) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/venv/lib/python3.10/site-packages (from matplotlib->rl4fisheries==1.0.0) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/venv/lib/python3.10/site-packages (from matplotlib->rl4fisheries==1.0.0) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/venv/lib/python3.10/site-packages (from matplotlib->rl4fisheries==1.0.0) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->rl4fisheries==1.0.0) (1.16.0)\n",
      "Building wheels for collected packages: rl4fisheries\n",
      "  Building editable for rl4fisheries (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rl4fisheries: filename=rl4fisheries-1.0.0-0.editable-py3-none-any.whl size=2176 sha256=aebb65ca4f07d99d588c7fb0de18b7cdbb9aff0bb29ab44fe3dd315eb92caf22\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-t5m_i4it/wheels/d3/ce/fe/d5af67bb4edf309f6a59d59140b2b78d5a336b2ad4b93a1fb4\n",
      "Successfully built rl4fisheries\n",
      "Installing collected packages: rl4fisheries\n",
      "  Attempting uninstall: rl4fisheries\n",
      "    Found existing installation: rl4fisheries 1.0.0\n",
      "    Uninstalling rl4fisheries-1.0.0:\n",
      "      Successfully uninstalled rl4fisheries-1.0.0\n",
      "Successfully installed rl4fisheries-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-optimize in /opt/venv/lib/python3.10/site-packages (0.9.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/venv/lib/python3.10/site-packages (from scikit-optimize) (1.3.2)\n",
      "Requirement already satisfied: pyaml>=16.9 in /opt/venv/lib/python3.10/site-packages (from scikit-optimize) (23.12.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/venv/lib/python3.10/site-packages (from scikit-optimize) (1.26.4)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/venv/lib/python3.10/site-packages (from scikit-optimize) (1.12.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /opt/venv/lib/python3.10/site-packages (from scikit-optimize) (1.4.0)\n",
      "Requirement already satisfied: PyYAML in /opt/venv/lib/python3.10/site-packages (from pyaml>=16.9->scikit-optimize) (6.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/venv/lib/python3.10/site-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -e ..\n",
    "# %pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8a7920aa-5e69-4690-be6d-f03308ddf449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl4caribou import Caribou\n",
    "from skopt import gp_minimize, gbrt_minimize\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from plotnine import ggplot, aes, geom_point, geom_ribbon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49794040-34a0-4491-8a3d-12ad3f114068",
   "metadata": {},
   "source": [
    "Here is an example of a simple fixed action policy.  It will apply a fixed hunting effort (potentially zero) each year to Moose, and another fixed effort to Wolves.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "51c9e6d9-9299-4296-b647-cf498b0b92cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class fixed_effort:\n",
    "    def __init__(self, action):\n",
    "        self.effort = np.array(action, dtype=np.float32)\n",
    "\n",
    "    def predict(self, observation, **kwargs):\n",
    "        action = self.effort * 2 - 1\n",
    "        return action, {}\n",
    "\n",
    "pacifist = fixed_effort([0., 0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cdeb4bd8-9620-4c4f-829d-a3a2c0e8dfd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.4943695 , -0.48672426, -0.8089408 ], dtype=float32),\n",
       " 0.250531405210495,\n",
       " False,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = Caribou()\n",
    "obs = env.reset()\n",
    "action, _ = pacifist.predict(obs)\n",
    "env.step(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5b4db8-e98f-482e-b2b8-751bee389cc1",
   "metadata": {},
   "source": [
    "## Fixed policy evaluation helpers\n",
    "\n",
    "This function simulates the dynamics under any given manager.  Each timestep, the manager gets an observation of the population (Caribou, Moose, Wolves), and decides (\"predicts\") what harvest action to take on wolves and moose to maximize the overall net utility over the full simulation.\n",
    "\n",
    "A helper utility runs this simulation 10 times and returns the mean and summary statistics.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6fa4681c-fbca-4ade-a8ab-e021cd9d07e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_ep_rew(manager, env):\n",
    "    episode_reward = 0.0\n",
    "    observation, _ = env.reset()\n",
    "    for t in range(env.Tmax):\n",
    "        action, _ = manager.predict(observation)\n",
    "        observation, reward, terminated, done, info = env.step(action)\n",
    "        episode_reward += reward\n",
    "        if terminated or done:\n",
    "            break\n",
    "    return episode_reward\n",
    "\n",
    "def gather_stats(manager, env, N=10):\n",
    "    results = [gen_ep_rew(manager, env) for _ in range(N)]\n",
    "    y = np.mean(results)\n",
    "    sigma = np.std(results)\n",
    "    ymin = y - sigma\n",
    "    ymax = y + sigma\n",
    "    return y, ymin, ymax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f3ddd3b8-6696-4f0d-a9a1-c6d722deb3b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23.70720968544483, 5.766838293769911, 41.64758107711975)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_ep_rew(pacifist, env)\n",
    "gather_stats(pacifist, env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cc6d29-7dde-4785-9f64-8562ce093f36",
   "metadata": {},
   "source": [
    "## Determine optimal mortality policy\n",
    "\n",
    "Use Bayesian optimization techniques for nonlinear and stochastic functions from Scikit-Optimize (e.g. Gaussian Process estimation) to estimate the optimal fixed mortality policy for both wolves and moose: (err, maybe this can be done analytically too).  Note we define the function to be minimized, `g(x)` as a function of the actions, `x`. Note we report the _negative_ mean reward since the optimizer tries to _minimize_ the value.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d876df99-b2ab-49ab-aaa0-3b545cc7ae4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(x):\n",
    "    manager = fixed_effort(x)\n",
    "    out = gather_stats(manager, env)\n",
    "    return - out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "812edc32-f0f9-4ff4-9792-77acf6962179",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 42s, sys: 9min 48s, total: 12min 31s\n",
      "Wall time: 1min 40s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-192.28646437703884, [0.17790704682764627, 0.061024282615602])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "res = gp_minimize(g, [(0.0, 0.3), (0, 0.3)], n_calls = 300)\n",
    "res.fun, res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4c5c2ec8-f61b-4dae-bc1b-ba70310a694b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 41s, sys: 644 ms, total: 3min 42s\n",
      "Wall time: 3min 40s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-183.45138428616946, [0.1625976286665279, 0.05916838814404951])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "res = gbrt_minimize(g, [(0.0, 0.3), (0, 0.3)], n_calls = 300)\n",
    "res.fun, res.x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
